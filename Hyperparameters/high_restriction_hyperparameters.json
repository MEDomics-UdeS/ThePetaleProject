{
    "lr":{
        "min": 1e-5,
        "max": 5e-5
    },
    "batch_size":{
        "min": 10,
        "max": 11
    },
    "n_layers":{
        "min": 1,
        "max": 2
    },
    "n_units":{
        "min": 1,
        "max": 10
    },
    "dropout":{
        "min":0.3,
        "max":0.31
    },
    "activation":{
        "values": ["ReLU"]
    },
    "weight_decay": {
        "min": 5e-3,
        "max": 8e-3
    }

}